{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import basic libraries"
      ],
      "metadata": {
        "id": "qkFW2x8GVkLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VVX_-wKyixl4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "import random\n",
        "import pymysql"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch data from SQL server to Python"
      ],
      "metadata": {
        "id": "UDV0aHw1VQSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "host = \"localhost\"\n",
        "port= 3306\n",
        "database = 'burger_sales'\n",
        "user = 'root'\n",
        "password = 'ranjeetjb'\n",
        "\n",
        "conn = pymysql.connect(host=host,\n",
        "                      user=user,\n",
        "                      password=password,\n",
        "                      database=database,\n",
        "                      port=port)\n",
        "query = \"SELECT * FROM burger_sales_data;\"\n",
        "df=pd.read_sql(query, conn)\n",
        "conn.close()\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA32ikQ5i5-f",
        "outputId": "ad8ba174-a051-4805-9367-c473ed1c7737"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Ranjeet Kumar\\AppData\\Local\\Temp\\ipykernel_15528\\3162228948.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df=pd.read_sql(query, conn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date Region  Temperature  Humidity       Wind  Visibility  \\\n",
            "0  15-09-2020   Reg1    10.248814  0.779164  11.509130   14.503403   \n",
            "1  14-09-2020   Reg1    10.337595  0.908549   7.432656    2.232960   \n",
            "2  13-09-2020   Reg1    20.763686  0.505324   7.788249    4.779211   \n",
            "3  12-09-2020   Reg1    21.500892  0.758557   3.767432    9.904534   \n",
            "4  11-09-2020   Reg1    21.774269  0.398296  20.705369   15.224605   \n",
            "\n",
            "      Pressure    Sales  \n",
            "0  1017.293917   991.60  \n",
            "1  1019.452636  1858.59  \n",
            "2  1022.677119     3.99  \n",
            "3  1009.341357  3090.78  \n",
            "4  1015.713234   990.99  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "R0fdhIRfVvpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Handle missing values, outliers, and feature engineering.\"\"\"\n",
        "    # 1. Handle Missing Values\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df[['Temperature', 'Humidity', 'Wind', 'Visibility', 'Pressure', 'Sales']] = imputer.fit_transform(df[['Temperature', 'Humidity', 'Wind', 'Visibility', 'Pressure', 'Sales']])\n",
        "\n",
        "    # 2. Handle Outliers using Z-score method\n",
        "    z_scores = np.abs(zscore(df[['Temperature', 'Humidity', 'Wind', 'Visibility', 'Pressure', 'Sales']]))\n",
        "    threshold = 3\n",
        "    df_no_outliers = df[(z_scores < threshold).all(axis=1)]\n",
        "\n",
        "    # 3. Feature Engineering: Lag Features and Rolling Mean\n",
        "    df_no_outliers['Sales_lag_1'] = df_no_outliers['Sales'].shift(1)\n",
        "    df_no_outliers['Sales_lag_7'] = df_no_outliers['Sales'].shift(7)\n",
        "    df_no_outliers['Sales_rolling_mean_7'] = df_no_outliers['Sales'].rolling(window=7).mean()\n",
        "    df_no_outliers.dropna(inplace=True)  # Drop NaN values created by lag features and rolling mean\n",
        "\n",
        "    return df_no_outliers\n",
        "\n",
        "# Prepare Data for LSTM\n",
        "def prepare_data(df, window_size=30):\n",
        "    \"\"\"Prepare time series data for LSTM.\"\"\"\n",
        "    sales = df['Sales'].values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))  # Scale data to range (0, 1)\n",
        "    scaled_sales = scaler.fit_transform(sales)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(scaled_sales)):\n",
        "        X.append(scaled_sales[i-window_size:i, 0])\n",
        "        y.append(scaled_sales[i, 0])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))  # 3D shape for LSTM (samples, timesteps, features)\n",
        "\n",
        "    return X, y, scaler"
      ],
      "metadata": {
        "id": "_ymZchRPjBIg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build LSTM model"
      ],
      "metadata": {
        "id": "BZ9rl0yQV1HT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build LSTM model with hyperparameters\n",
        "def build_model(units1, units2, dropout_rate, learning_rate):\n",
        "    \"\"\"Build and compile the LSTM model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=units1, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=units2, return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1))  # Single output node for regression\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Random Search for Hyperparameters\n",
        "def random_search_hyperparameters(X_train, y_train, X_val, y_val, n_iter=20):\n",
        "    \"\"\"Randomly search for the best hyperparameters for LSTM.\"\"\"\n",
        "    best_score = float('inf')\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        print(f\"Random Search Iteration: {i+1}/{n_iter}\")\n",
        "\n",
        "        # Randomly select hyperparameters\n",
        "        units1 = random.choice([32, 64, 128, 256])\n",
        "        units2 = random.choice([32, 64, 128, 256])\n",
        "        dropout_rate = random.uniform(0.1, 0.5)\n",
        "        learning_rate = 10 ** random.uniform(-4, -2)\n",
        "\n",
        "        print(f\"Testing Hyperparameters: units1={units1}, units2={units2}, dropout_rate={dropout_rate:.4f}, learning_rate={learning_rate:.6f}\")\n",
        "\n",
        "        # Build and train the model\n",
        "        model = build_model(units1, units2, dropout_rate, learning_rate)\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "        history = model.fit(X_train, y_train, epochs=30, batch_size=32,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=1)\n",
        "\n",
        "        val_loss = min(history.history['val_loss'])\n",
        "        print(f\"Validation Loss: {val_loss}\")\n",
        "\n",
        "        if val_loss < best_score:\n",
        "            best_score = val_loss\n",
        "            best_params = {'units1': units1, 'units2': units2, 'dropout_rate': dropout_rate, 'learning_rate': learning_rate}\n",
        "            best_model = model\n",
        "\n",
        "    return best_model, best_params, best_score"
      ],
      "metadata": {
        "id": "E3wcHe_rzCGw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = preprocess_data(df)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "WF4cZuNa1Ffo",
        "outputId": "f3fbca20-3df2-4e70-a613-a4f80b8298b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Ranjeet Kumar\\AppData\\Local\\Temp\\ipykernel_15528\\2885962469.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_no_outliers['Sales_lag_1'] = df_no_outliers['Sales'].shift(1)\n",
            "C:\\Users\\Ranjeet Kumar\\AppData\\Local\\Temp\\ipykernel_15528\\2885962469.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_no_outliers['Sales_lag_7'] = df_no_outliers['Sales'].shift(7)\n",
            "C:\\Users\\Ranjeet Kumar\\AppData\\Local\\Temp\\ipykernel_15528\\2885962469.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_no_outliers['Sales_rolling_mean_7'] = df_no_outliers['Sales'].rolling(window=7).mean()\n",
            "C:\\Users\\Ranjeet Kumar\\AppData\\Local\\Temp\\ipykernel_15528\\2885962469.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_no_outliers.dropna(inplace=True)  # Drop NaN values created by lag features and rolling mean\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date Region  Temperature  Humidity       Wind  Visibility  \\\n",
              "7   08-09-2020   Reg1    25.493278  0.428529  18.176798   14.406207   \n",
              "8   07-09-2020   Reg1    23.472156  0.464102   8.725919    4.130202   \n",
              "9   06-09-2020   Reg1    24.451157  0.686122   6.219998   10.344838   \n",
              "10  05-09-2020   Reg1    25.494625  0.401804  19.308957   14.123511   \n",
              "11  04-09-2020   Reg1    25.673838  0.500355  10.796126    6.519813   \n",
              "\n",
              "       Pressure    Sales  Sales_lag_1  Sales_lag_7  Sales_rolling_mean_7  \n",
              "7   1014.294212  1584.29      3353.17       991.60           1559.105714  \n",
              "8   1020.738999   107.60      1584.29      1858.59           1308.964286  \n",
              "9   1010.946550  3108.91       107.60         3.99           1752.524286  \n",
              "10  1016.493160   960.01      3108.91      3090.78           1448.128571  \n",
              "11  1018.567744   415.47       960.01       990.99           1365.911429  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Region</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind</th>\n",
              "      <th>Visibility</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Sales_lag_1</th>\n",
              "      <th>Sales_lag_7</th>\n",
              "      <th>Sales_rolling_mean_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>08-09-2020</td>\n",
              "      <td>Reg1</td>\n",
              "      <td>25.493278</td>\n",
              "      <td>0.428529</td>\n",
              "      <td>18.176798</td>\n",
              "      <td>14.406207</td>\n",
              "      <td>1014.294212</td>\n",
              "      <td>1584.29</td>\n",
              "      <td>3353.17</td>\n",
              "      <td>991.60</td>\n",
              "      <td>1559.105714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>07-09-2020</td>\n",
              "      <td>Reg1</td>\n",
              "      <td>23.472156</td>\n",
              "      <td>0.464102</td>\n",
              "      <td>8.725919</td>\n",
              "      <td>4.130202</td>\n",
              "      <td>1020.738999</td>\n",
              "      <td>107.60</td>\n",
              "      <td>1584.29</td>\n",
              "      <td>1858.59</td>\n",
              "      <td>1308.964286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>06-09-2020</td>\n",
              "      <td>Reg1</td>\n",
              "      <td>24.451157</td>\n",
              "      <td>0.686122</td>\n",
              "      <td>6.219998</td>\n",
              "      <td>10.344838</td>\n",
              "      <td>1010.946550</td>\n",
              "      <td>3108.91</td>\n",
              "      <td>107.60</td>\n",
              "      <td>3.99</td>\n",
              "      <td>1752.524286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>05-09-2020</td>\n",
              "      <td>Reg1</td>\n",
              "      <td>25.494625</td>\n",
              "      <td>0.401804</td>\n",
              "      <td>19.308957</td>\n",
              "      <td>14.123511</td>\n",
              "      <td>1016.493160</td>\n",
              "      <td>960.01</td>\n",
              "      <td>3108.91</td>\n",
              "      <td>3090.78</td>\n",
              "      <td>1448.128571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>04-09-2020</td>\n",
              "      <td>Reg1</td>\n",
              "      <td>25.673838</td>\n",
              "      <td>0.500355</td>\n",
              "      <td>10.796126</td>\n",
              "      <td>6.519813</td>\n",
              "      <td>1018.567744</td>\n",
              "      <td>415.47</td>\n",
              "      <td>960.01</td>\n",
              "      <td>990.99</td>\n",
              "      <td>1365.911429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting of data"
      ],
      "metadata": {
        "id": "FPD8QdokWEdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for LSTM\n",
        "X, y, scaler = prepare_data(df, window_size=30)\n",
        "\n",
        "# Split data into train and validation sets\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_val = X[:train_size], X[train_size:]\n",
        "y_train, y_val = y[:train_size], y[train_size:]\n"
      ],
      "metadata": {
        "id": "vfWsmaVWQeqi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of model"
      ],
      "metadata": {
        "id": "ct7b4P0dWI1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter search\n",
        "best_model, best_params, best_score = random_search_hyperparameters(X_train, y_train, X_val, y_val, n_iter=20)\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Validation Loss: {best_score}\")\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = best_model.predict(X_val)"
      ],
      "metadata": {
        "id": "sB05FfXF1Ft1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics** calculated"
      ],
      "metadata": {
        "id": "92C62iF9WOk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-Squared (R2): {r2}\")\n",
        "\n",
        "# Plot actual vs predicted sales\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_val, label='Actual Sales')\n",
        "plt.plot(y_pred, label='Predicted Sales')\n",
        "plt.legend()\n",
        "plt.title('Actual vs Predicted Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "43qvYSvs1gfH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "collapsed": true,
        "outputId": "b4d8f6c9-68ff-4f81-8eb5-527a6b69ab3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate evaluation metrics\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_val, \u001b[43my_pred\u001b[49m))\n\u001b[0;32m      3\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_val, y_pred)\n\u001b[0;32m      4\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_val, y_pred)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model to Keras"
      ],
      "metadata": {
        "id": "CBk8tvgAW4WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model('sales_forecasting_lstm_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de-Jcj0bvoDU",
        "outputId": "47bd94a1-f001-4a76-fff3-d6bf48104af1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Ranjeet Kumar\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 10 variables whereas the saved optimizer has 18 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "IC5ZmA_5XArT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume X_val is the validation data you want to predict on\n",
        "predictions = loaded_model.predict(X_val)\n",
        "\n",
        "# Print first 5 predictions\n",
        "print(predictions[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7sFjK9AvoLC",
        "outputId": "b3df07c2-4f23-4ef4-e779-543af0fda7cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
            "[[0.30338556]\n",
            " [0.6905669 ]\n",
            " [0.1681576 ]\n",
            " [0.70780647]\n",
            " [0.23367608]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation on validation set"
      ],
      "metadata": {
        "id": "nQodVAtdXEd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "loss, mae = loaded_model.evaluate(X_val, y_val)\n",
        "print(f\"Loss: {loss}, Mean Absolute Error (MAE): {mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDUKXmqOvoUL",
        "outputId": "e86d6033-a282-4db5-a134-db97aafcd529"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0626 - mae: 0.2049\n",
            "Loss: 0.06079982593655586, Mean Absolute Error (MAE): 0.20116250216960907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actual sales"
      ],
      "metadata": {
        "id": "NmmDZW6eXQr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example predictions (replace this with your predictions)\n",
        "scaled_predictions = np.array([[0.30338556], [0.6905669], [0.1681576], [0.70780647], [0.23367608]])\n",
        "\n",
        "# Inverse transform the predictions\n",
        "predicted_sales = scaler.inverse_transform(scaled_predictions)\n",
        "\n",
        "# Print results\n",
        "print(\"Predicted Sales (Actual Scale):\", predicted_sales)\n"
      ],
      "metadata": {
        "id": "IpvuF4ivxgX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29e960c-5614-4db2-c017-973700283474"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sales (Actual Scale): [[1081.54142235]\n",
            " [2461.60284702]\n",
            " [ 599.53758629]\n",
            " [2523.05122554]\n",
            " [ 833.07034603]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Burger forecasting sales for 5 days"
      ],
      "metadata": {
        "id": "AqydKEO5ZtXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract recent 'Sales' data only (same as training)\n",
        "window_size = 5\n",
        "\n",
        "\n",
        "latest_sales = df['Sales'].values[-window_size:].reshape(-1, 1)\n",
        "\n",
        "# Scale using the original 'Sales' scaler\n",
        "scaled_latest_sales = scaler.transform(latest_sales)\n",
        "\n",
        "# Reshape to match LSTM input (1, 30, 1)\n",
        "X_input = np.reshape(scaled_latest_sales, (1, window_size, 1))\n",
        "\n",
        "# Make prediction\n",
        "next_day_prediction = loaded_model.predict(X_input)\n",
        "\n",
        "# Inverse transform the prediction\n",
        "actual_prediction = scaler.inverse_transform(next_day_prediction)\n",
        "\n",
        "print(\"Forecasted Sales for Next Day:\", actual_prediction[0][0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFd_pSriTfv-",
        "outputId": "13127b2d-3030-4639-b319-5f7181ec7fc2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step\n",
            "Forecasted Sales for Next Day: 690.4345\n"
          ]
        }
      ]
    }
  ]
}